# ğŸ—£ï¸ Tamil Whisper STT: Efficient Speech-to-Text for Tamil

Welcome to **Tamil Whisper STT** â€“ an open-source, production-ready pipeline for high-quality Tamil speech-to-text (STT) using state-of-the-art Whisper models. This project is designed for fast, accurate, and resource-efficient transcription, making it ideal for deployment on small devices and scalable systems alike.

---

## ğŸš€ Features

- **Fine-tuned Whisper Tiny Model**: Custom-trained on the Indic Tamil dataset for optimal Tamil ASR performance.
- **End-to-End Pipeline**: From data preprocessing to model training and fast inference.
- **Multi-Device Support**: Seamless GPU/CPU compatibility.
- **Fast Inference**: Leverage [faster-whisper](https://github.com/SYSTRAN/faster-whisper) for blazing-fast transcription.
- **Open & Reproducible**: All scripts, notebooks, and utilities included for full transparency and reproducibility.

---

## ğŸ“‚ Project Structure

```
dataset/
â”œâ”€â”€ wavs_original/         # Raw audio files (.wav)
â”œâ”€â”€ wavs_converted/        # Audio files converted to 16kHz mono
â”œâ”€â”€ metadata.csv           # Training metadata (filtered, CSV)
â”œâ”€â”€ metadata.txt           # Raw metadata (TXT)
convert_audio_sample_rate.sh  # Audio conversion script
metadata_pre.py               # Metadata preprocessing script
fine_tune_whisper.ipynb       # Model fine-tuning notebook
fine_tuned_inference.py       # Inference with fine-tuned model
original_inference.py         # Inference with base Whisper model
fast_inference.py             # Fast inference using faster-whisper
requirements.txt              # Python dependencies
test.wav                      # Example audio file
readme.md                     # Project documentation
```

---

## ğŸ Quickstart

### 1ï¸âƒ£ Prepare Metadata

Ensure your metadata is in the correct format and transcriptions are less than 447 tokens.

```txt
train_tamilfem_05396    à®…à®¤à¯à®•à¯à®•à¯ à®…à®ªà¯à®ªà¯à®±à®®à®¾ à®…à®µà®©à¯‹à®Ÿ à®ªà¯à®•à®´à¯ à®‰à®²à®•à®®à¯ à®®à¯à®´à¯à®šà¯à®®à¯ à®ªà®°à®µà¯à®®à¯à®©à¯ à®šà¯Šà®©à¯à®©à®¾à®°à¯ .
```

- **Convert and filter metadata:**
  ```sh
  python metadata_pre.py
  ```
  See `metadata_pre.py` for details.

### 2ï¸âƒ£ Convert Audio

Convert all audio files to 16kHz mono for Whisper compatibility.

```sh
bash convert_audio_sample_rate.sh
```
See `convert_audio_sample_rate.sh`.

### 3ï¸âƒ£ Fine-Tune Whisper Model

Train the Whisper Tiny model on your dataset.

- Open and run `fine_tune_whisper.ipynb` for step-by-step fine-tuning.
- Uses HuggingFace Transformers and Datasets.

### 4ï¸âƒ£ Inference

#### a. **Fine-Tuned Model**
```sh
python fine_tuned_inference.py
```
- See `fine_tuned_inference.py`.

#### b. **Original Whisper Model**
```sh
python original_inference.py
```
- See `original_inference.py`.

#### c. **Fast Inference (faster-whisper)**
```sh
python fast_inference.py
```
- See `fast_inference.py`.

---

## ğŸ§‘â€ğŸ’» Technical Highlights

- **Data Preprocessing**: `metadata_pre.py` ensures only valid-length transcriptions are used.
- **Audio Conversion**: `convert_audio_sample_rate.sh` standardizes audio for training/inference.
- **Model Training**: `fine_tune_whisper.ipynb` leverages HuggingFace's Trainer API with a custom data collator for efficient batching.
- **Inference**: Multiple scripts for benchmarking and deployment:
  - `fine_tuned_inference.py`: Inference with your fine-tuned model.
  - `original_inference.py`: Baseline inference with the original Whisper Tiny.
  - `fast_inference.py`: Ultra-fast inference using [faster-whisper](https://github.com/SYSTRAN/faster-whisper).

---

## ğŸ“¦ Requirements

- Python 3.10+
- [transformers](https://github.com/huggingface/transformers)
- [datasets](https://github.com/huggingface/datasets)
- [faster-whisper](https://github.com/SYSTRAN/faster-whisper)
- sox (for audio conversion)

Install dependencies:
```sh
pip install -r requirements.txt
```

---

## ğŸ“ Citation

If you use this project, please consider citing or starring the repository!

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome! Please open an issue or submit a pull request.


---

## ğŸ“¬ Contact

For questions or collaborations, please open an issue or reach out via GitHub.

---

**Empowering Tamil language technology, one open-source model

